{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed Information Systems\n",
    "\n",
    "***Final Exam, Spring Semester, 2019***\n",
    "\n",
    "The exam will be held on your computer, but digital communication by any means is **strictly prohibited**. You are allowed, though, to use *StackOverflow* or similar websites to resolve syntax-related Python errors. \n",
    "The following materials are also allowed: exercise sheets and solutions, past exams with your own solution, personally written notes and personally collected documentation.\n",
    "By participating in this exam you **agree to these conditions**.\n",
    "\n",
    "These are the instructions for the exam:\n",
    "\n",
    "- You are not allowed to leave the examination room in the first 20 and the last 15 minutes of the exam.\n",
    "- The quiz will remain open **only for the first 2 hours** of the exam to avoid network congestion.\n",
    "- **30 minutes** before the end of the exam we will announce a password to upload your jupyter notebook on Moodle.\n",
    "- It is not recommended to leave the exam before the password is published. If you need to leave earlier, contact us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#0-Rename-your-Notebook\" data-toc-modified-id=\"0-Rename-your-Notebook-0\">0 Rename your Notebook</a></span></li><li><span><a href=\"#1-Multiple-Choice-Questions\" data-toc-modified-id=\"1-Multiple-Choice-Questions-1\">1 <a href=\"https://moodle.epfl.ch/mod/quiz/view.php?id=1026316\" target=\"_blank\">Multiple Choice Questions</a></a></span></li><li><span><a href=\"#2-Implementing-a-Rule-Based-Approach-for-Entity-Disambiguation\" data-toc-modified-id=\"2-Implementing-a-Rule-Based-Approach-for-Entity-Disambiguation-2\">2 Implementing a Rule-Based Approach for Entity Disambiguation</a></span><ul class=\"toc-item\"><li><span><a href=\"#2.1-Learning-rules\" data-toc-modified-id=\"2.1-Learning-rules-2.1\">2.1 Learning rules</a></span></li><li><span><a href=\"#2.2-Finding-new-rules-using-bootstrapping\" data-toc-modified-id=\"2.2-Finding-new-rules-using-bootstrapping-2.2\">2.2 Finding new rules using bootstrapping</a></span></li></ul></li><li><span><a href=\"#3-Academic-Communities\" data-toc-modified-id=\"3-Academic-Communities-3\">3 Academic Communities</a></span><ul class=\"toc-item\"><li><span><a href=\"#3.1-Modularity\" data-toc-modified-id=\"3.1-Modularity-3.1\">3.1 Modularity</a></span></li><li><span><a href=\"#3.2-Community-Detection\" data-toc-modified-id=\"3.2-Community-Detection-3.2\">3.2 Community Detection</a></span></li><li><span><a href=\"#3.3-Community-Influencers\" data-toc-modified-id=\"3.3-Community-Influencers-3.3\">3.3 Community Influencers</a></span></li><li><span><a href=\"#3.4-Connectivity-Based-Community-Ranking\" data-toc-modified-id=\"3.4-Connectivity-Based-Community-Ranking-3.4\">3.4 Connectivity-Based Community Ranking</a></span></li><li><span><a href=\"#3.5-Personalized-Community-Ranking\" data-toc-modified-id=\"3.5-Personalized-Community-Ranking-3.5\">3.5 Personalized Community Ranking</a></span></li><li><span><a href=\"#3.6-TF-IDF-Community-Ranking\" data-toc-modified-id=\"3.6-TF-IDF-Community-Ranking-3.6\">3.6 TF-IDF Community Ranking</a></span></li><li><span><a href=\"#3.7-Rankings-Correlation\" data-toc-modified-id=\"3.7-Rankings-Correlation-3.7\">3.7 Rankings Correlation</a></span></li></ul></li><li><span><a href=\"#4-Submit--your-Notebook\" data-toc-modified-id=\"4-Submit--your-Notebook-4\">4 <a href=\"https://moodle.epfl.ch/mod/quiz/view.php?id=1026302\" target=\"_blank\">Submit  your Notebook</a></a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Rename your Notebook\n",
    "Replace SciperNo with your **personal SCIPER Number**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 [Multiple Choice Questions](https://moodle.epfl.ch/mod/quiz/view.php?id=1026316)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Implementing a Rule-Based Approach for Entity Disambiguation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Learning rules\n",
    "\n",
    "We would like to develop a rule-based approach to disambiguate the meaning of the term \"Apple\" in sentences into the two possible meanings **Tech** and **Fruit**. The rules use keyphrases i.e., n-grams of words, as features in their conditions. In the approach **only the top-k keyphrases** are considered. Before forming keyphrases, the words are stemmed, stopwords are not considered and uppercase words are converted to lowercase.\n",
    "\n",
    "An example of a possible rule would be:\n",
    "\n",
    "\tif \"fruit\" and \"facebook\" then \"Tech\"\n",
    "\n",
    "meaning that if a sentence that contains the term \"Apple\" also contains the unigrams \"fruit\" and \"facebook\" then the meaning of \"Apple\" should be the Apple technology company (**Tech**).\n",
    "\n",
    "More generally we write such rules as:\n",
    "\n",
    "\t{k1,...,kn} -> Tech or {k1,...,kn} -> Fruit\n",
    "    \n",
    "where k1,..,kn are arbitrary word n-grams and a set {k1,...,kn} is considered as an item set.\n",
    "\n",
    "As **training data** we obtain 10 sentences containing \"Apple\" that have been labelled by their meaning as T(ech) or F(ruit).\n",
    "\n",
    "    An apple is a fruit and good for health. (F)\n",
    "    Apple is a tech company. (T)\n",
    "    Tech companies like Apple and Facebook have big data centers (T)\n",
    "    For maintaining health eat one apple a day. (F)\n",
    "    A new Apple data center has been opened next to the one of Facebook. (T)\n",
    "    Apple has sold 1 million units in one day. (T)\n",
    "    Fruits, like apples and pears, are contaminated with pesticides.  (F)\n",
    "    A fruit salad contains apples, bananas and pears.  (F)\n",
    "    I saw a new apple recipe on Facebook.  (F)\n",
    "    Apple is increasingly processing health data. (T)\n",
    "\n",
    "**Stopwords** are: an, is, a, and, for, like, and, have, has, been, in, are, with, on, by, as, may, one, to, the, of.\n",
    "\n",
    "We define the **confidence** of a rule {k1,...,kn} -> T as the fraction between the number of sentences that contain all keyphrases k1,...,kn with label T over the number of sentences with all keyphrases k1,...,kn. Similar definition for {k1,...,kn} -> F.\n",
    "\n",
    "We define the **support** of an itemset as the number of sentences that contain all the n-grams in the itemset.\n",
    "\n",
    "**Questions:** \n",
    "1. Without considering the word \"apple\", determine the keyphrases with minimum document frequency of 2.\n",
    "2. Determine all itemsets of keyphrases with a minimum support of 2.\n",
    "3. Determine all rules that have a minimum support of 2 and a minimum confidence of 70%. Provide for each rule its support and confidence values. \n",
    "4. Explain how the apriori property could be exploited in optimizing the computation of those itemsets for composite keyphrases.\n",
    "\n",
    "Hint: the following are the top-10 document frequencies of terms.\n",
    "\n",
    "| Term        | Frequency           | \n",
    "| ------------- |:-------------:| \n",
    "|fruit | 3|\n",
    "|health | 3|\n",
    "|data | 3|\n",
    "|facebook | 3|\n",
    "|tech | 2|\n",
    "|compani | 2|\n",
    "|center | 2|\n",
    "|day | 2|\n",
    "|new | 2|\n",
    "|pear |2|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***ANSWER:***\n",
    "1. Fruit, health, data center, facebook, tech compani, new, pear, day, data\n",
    "2. {Fruit, pears}, {Facebook, data center}, {fruit}, {health}, {data center}, {facebook}, {tech compani}, {new}, {pear}, {day}, {data}\n",
    "3. \n",
    " * {data center, facebook} -> T (support 2, confidence 100%)\n",
    " * {data center} -> T (support 2, confidence 100%)\n",
    " * {tech compani} -> T (support 2, confidence 100%)\n",
    " * {data} -> T (support 3, confidence 100%)\n",
    " * {fruit} -> F (support 3, confidence 100%)\n",
    " * {fruits, pear} -> F (support 2, confidence 100%)\n",
    " * {pear} -> F (support 2, confidene 100%)\n",
    " * {data} -> T (support 3, confidence 100%)\n",
    " \n",
    "4. We know that any subset of a frequent itemset is necessarily also a frequent itemset. So we could programatically go from big itemsets, checking one by one, decreasing size. And once an itemset is found to have sufficient support, we know each subsets have sufficient support, and we don't have to check for them. Then computing confidence becomes faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Finding new rules using bootstrapping\n",
    "\n",
    "We are using the rules we have learnt now to find new sentences on Apple (e.g. using Google search) to increase our training data and thus learning new rules.\n",
    "\n",
    "Performing this approach we found 10 more sentences:\n",
    "\n",
    "    Apple and Facebook data center filed plans to expand data center operations in Prineville (T) \n",
    "    Apple, Facebook, Google Asked to Pay for Wind Parks in Denmark (T) \n",
    "    Google, Facebook and Apple lead on green data centers (T)\n",
    "    Apple to contest patent filed by Google. (T) \n",
    "    Green data centers are the new priority for Apple and Google. (T)\n",
    "    Green apples are an ideal ingredient for fruit salad. (F)\n",
    "    Apple Pears have been described as the hottest new item since the Kiwi (F)\n",
    "    Join Facebook to connect with Apples Pear and others you may know (F)\n",
    "    An apple is a sweet, edible fruit produced by an apple tree (F)\n",
    "    An apple a day keeps the doctor away (F)\n",
    "\n",
    "**Questions:** \n",
    "\n",
    "1. Given that the size of the training set has increased, should confidence and/or support threshold be adapted and how?\n",
    "2. Identify all new rules with adapted confidence and support threshold that can be derived from the training set that has been enlarged by the examples that have been retrieved using a bootstrapping approach.\n",
    "3. Once you found a new rule, explain how you would proceed to verify that the new rule does not introduce semantic shift."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***ANSWER:***\n",
    "1. Yes, they must be updated but it can be done \"on-the-fly\", without having to do the actual computation. Because if before an itemset had a confidence of 8/10, we bootstrap a new sentence and obtain a confidence of 9/11. This is different, but by the nature of bootstrap, we already know that our itemset is in the sentence, and we know the label. Thus each new sample adds 1 to the support and increases the confidence ($\\frac{x}{y} \\to \\frac{x+1}{y+1}$) of the itemset.\n",
    "2. \n",
    "3. I would check the combination of the original rule and the new one still gives acceptable results. If they drifted too much, the combination of the original itemset and the new one would have very low support and confidence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Academic Communities\n",
    "The dataset you are about to explore is a snapshot of the **retweet network** among official accounts of universities and academic institutes. The **nodes** of the network are twitter handles (usernames), while the **edges** are attributed with a **label**, which was extracted from the topic of the tweet, and a **weight**, which depicts the popularity of the original tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from networkx.algorithms import community\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_pandas_edgelist(pd.read_csv('uni_network.csv'), 'Source', 'Target', edge_attr=['Label', 'Weight'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Modularity\n",
    "- Implement the modularity metric for communities.\n",
    "- Use the toy example and the assertion below to validate your results.\n",
    "- Hint: You can reuse code from the exercise sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def communities_modularity(G, nodes_community):\n",
    "    ''' input: G:nx.Graph \n",
    "               nodes_community:{node_id:community_id}\n",
    "       output: Q (modularity metric)\n",
    "    '''\n",
    "    Q = 0\n",
    "    \n",
    "    m = len(G.edges)\n",
    "    for node_i in G.nodes:\n",
    "        for node_j in G.nodes:\n",
    "            if nodes_community[node_i] == nodes_community[node_j]:\n",
    "                Q += G.number_of_edges(node_i, node_j) - G.degree[node_i]*G.degree[node_j]/(2*m)\n",
    "    Q = Q/(2*m)\n",
    "    return Q \n",
    "\n",
    "Q = communities_modularity(nx.Graph([(1, 2), (2, 3), (3, 1)]), {1:'a', 2:'a', 3:'a'})\n",
    "assert (round(Q, 4) == 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Community Detection\n",
    "\n",
    "- In the following cells you are given two snippets of code for community detection:\n",
    "    - The first approach (`network_structure_communities`) computes communities based on the **network structure**. The algorithm that is used is the *Clauset-Newman-Moore greedy modularity maximization* and is similar to the *Louvain modularity maximization*.\n",
    "    - The second approach (`nodes_label_communities`) computes communities based on the **labels of the graph nodes**. The label of a node is determined by the dominant label of its edges. All nodes with the same label belong to the same community.\n",
    "\n",
    "- Based on the statistics that we present below, discuss what are the **pros and cons** of each approach.\n",
    "- Note: You don't have to code for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_structure_communities(G):\n",
    "    nodes_community = community.greedy_modularity_communities(G, weight='Weight')\n",
    "    nodes_community = {i:indx for indx, c in enumerate(nodes_community) for i in c}\n",
    "    nodes_community = {n:nodes_community[n] for n in G.nodes}\n",
    "    return nodes_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nodes_label_communities(G):\n",
    "    nodes_community = {}\n",
    "    for n in G.nodes():\n",
    "        labels = [[e[2]['Label']]*e[2]['Weight'] for e in G.edges(n, data=True)]\n",
    "        labels = [item for l in labels for item in l]\n",
    "        nodes_community[n] = max(set(labels), key = labels.count)\n",
    "    return nodes_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average Community Size</th>\n",
       "      <th>Communities Count</th>\n",
       "      <th>Modularity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1st approach</th>\n",
       "      <td>3.192053</td>\n",
       "      <td>453</td>\n",
       "      <td>0.919974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2nd approach</th>\n",
       "      <td>48.200000</td>\n",
       "      <td>30</td>\n",
       "      <td>0.688896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Average Community Size  Communities Count  Modularity\n",
       "                                                                   \n",
       "1st approach                3.192053                453    0.919974\n",
       "2nd approach               48.200000                 30    0.688896"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compare_approaches(G):\n",
    "    nodes_community_1 = network_structure_communities(G)\n",
    "    nodes_community_2 = nodes_label_communities(G)\n",
    "    communities_count_1 = len(set(nodes_community_1.values()))\n",
    "    communities_count_2 = len(set(nodes_community_2.values()))\n",
    "\n",
    "    return pd.DataFrame.from_dict([{'':'1st approach', 'Communities Count':communities_count_1, 'Average Community Size':len(G.nodes())/communities_count_1, 'Modularity':communities_modularity(G, nodes_community_1)},\\\n",
    "                                   {'':'2nd approach', 'Communities Count':communities_count_2, 'Average Community Size':len(G.nodes())/communities_count_2, 'Modularity':communities_modularity(G, nodes_community_2)}]).set_index('')\n",
    "\n",
    "compare_approaches(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***ANSWER:***\n",
    "The second approach solely relies on the labels to create the communities. Thus, the number of possible communities is bounded by the number of different labels (but not necessarily equal). This is good to avoid an explosion of the communities count (as we see), but may be too restrictive (a person that tweets 3 times, with 2 being about social media may not be good enough to classify this person as related to social media).\n",
    "\n",
    "The fist approach, on the other hand, is more robust to this problem, but can only create communities if they actually have an edge between them. As we can see below, a whooping majority of nodes have less than 3 edges, while a small number are hyperconnected. Also, there are a lot of small components (with 1-5 people inside), and 1-2 enormous components. \n",
    "The Louvain algorithm, while efficient, can't do anything good on components of such small size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 453 connected components\n"
     ]
    }
   ],
   "source": [
    "print(\"There are {} connected components\".format(nx.number_connected_components(G)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import collections\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "degree_sequence = sorted([d for n, d in G.degree()], reverse=True)  # degree sequence\n",
    "degreeCount = collections.Counter(degree_sequence)\n",
    "deg, cnt = zip(*degreeCount.items())\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.bar(deg, cnt, width=0.80, color='b')\n",
    "plt.title(\"Nodes degree distribution\")\n",
    "plt.xlabel('Degree')\n",
    "plt.ylabel(\"Count of nodes\")\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following tasks we will use the communities that are detected by the **second approach**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_community = nodes_label_communities(G)\n",
    "communities = list(set(nodes_community.values()))\n",
    "communities_count = len(communities)\n",
    "default_ranking = {c:0.0 for c in communities}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Community Influencers\n",
    "- Isolate each community from the graph. \n",
    "- Select the node with the **maximum pagerank** within each community as the **influencer** of that community.\n",
    "- Break ties arbitrarily.\n",
    "- Hint: Useful functions: `nx.pagerank()`, `G.subgraph()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('architecture', 'oxford_brookes'),\n",
       " ('artificial intelligence', 'univgroningen'),\n",
       " ('astronomy', 'jodrellbank'),\n",
       " ('biological', 'uptecporto'),\n",
       " ('cancer', 'SwanseaUni'),\n",
       " ('cell', 'GilesYeo'),\n",
       " ('chemistry', 'unisouthampton'),\n",
       " ('climate change', 'UniofExeter'),\n",
       " ('computer science', 'UniofHerts'),\n",
       " ('criminology', 'AngliaRuskin'),\n",
       " ('cyber security', 'DavidBugnon'),\n",
       " ('diabetes', 'BodleianHCL'),\n",
       " ('drones', 'HarperAdamsUni'),\n",
       " ('economics', 'KingsCollegeLon'),\n",
       " ('entrepreneurship', 'StaffsUni'),\n",
       " ('geography', 'UniSouthWales'),\n",
       " ('healthcare', 'VoiceofNursing_'),\n",
       " ('infection', 'UofGMVLS'),\n",
       " ('innovation', 'tcddublin'),\n",
       " ('medicine', 'sheffielduni'),\n",
       " ('neuroscience', 'aidanhorner'),\n",
       " ('pathways', 'univofstandrews'),\n",
       " ('patients', 'ThinkUHI'),\n",
       " ('physicist', 'royalsociety'),\n",
       " ('physics', 'ucl'),\n",
       " ('psychology', 'UniKent'),\n",
       " ('robotics', 'Phil_Baty'),\n",
       " ('social media', 'NYDailyNews'),\n",
       " ('sustainability', 'UniversityLeeds'),\n",
       " ('therapy', 'HANnl')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def community_influencers(G, nodes_community, communities, communities_count):\n",
    "    ''' input: G:nx.Graph \n",
    "               nodes_community:{node_id:community_id}\n",
    "               communities:[community_ids]\n",
    "               community_count:int\n",
    "       output: influencers:{community_id:node_id}\n",
    "    '''\n",
    "    influencers = {}\n",
    "    \n",
    "    #reverse nodes_communities\n",
    "    people_per_community = {commun: [] for commun in communities} # type: dict{community -> [list people]}\n",
    "    for person in nodes_community:\n",
    "        commun = nodes_community[person]\n",
    "        people_per_community[commun].append(person)\n",
    "    pagerank = (nx.pagerank(G))\n",
    "    \n",
    "    #identify leaders\n",
    "    for commun in people_per_community:\n",
    "        #for each community\n",
    "        leader = (None, 0)\n",
    "        for member in people_per_community[commun]:\n",
    "            #for all people of that community\n",
    "            if pagerank[member] > leader[1]:\n",
    "                #if the pagerank is better than the current best, update\n",
    "                leader = (member, pagerank[member])\n",
    "        influencers[commun] = leader[0]\n",
    "    return influencers\n",
    "\n",
    "influencers = community_influencers(G, nodes_community, communities, communities_count)\n",
    "sorted(influencers.items(), key=lambda x: x[0]) if influencers != {} else None # prints sorted results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Connectivity-Based Community Ranking\n",
    "- Compute a meta graph where nodes are communities and edges denote inter-connections across communities. \n",
    "- Add the weights of the inter-connections as weights to the edges.\n",
    "- Compute `pagerank` on the meta graph.\n",
    "- Hint: `w_matrix` is the confusion matrix of the weights among the communities. `w_matrix` is not symmetric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('innovation', 0.13354133213281),\n",
       " ('artificial intelligence', 0.108983425197368),\n",
       " ('psychology', 0.0672097589523473),\n",
       " ('computer science', 0.059207453865815246),\n",
       " ('sustainability', 0.048836911626010754),\n",
       " ('entrepreneurship', 0.04494490734282713),\n",
       " ('climate change', 0.03841862245006762),\n",
       " ('physics', 0.03515048605362855),\n",
       " ('architecture', 0.031158960354641302),\n",
       " ('economics', 0.030892992129275963),\n",
       " ('chemistry', 0.028897050367376068),\n",
       " ('biological', 0.02840194087073805),\n",
       " ('social media', 0.027800367317690713),\n",
       " ('robotics', 0.026814041823813195),\n",
       " ('healthcare', 0.02668302837256017),\n",
       " ('patients', 0.02657379832746347),\n",
       " ('cyber security', 0.026372303479866372),\n",
       " ('medicine', 0.024597623730958192),\n",
       " ('criminology', 0.021431848775623097),\n",
       " ('drones', 0.020434046557618928),\n",
       " ('cell', 0.01907827503165279),\n",
       " ('geography', 0.018947440941278756),\n",
       " ('therapy', 0.01856079578572953),\n",
       " ('diabetes', 0.017104995341539937),\n",
       " ('pathways', 0.01661833041170639),\n",
       " ('cancer', 0.015460503948890808),\n",
       " ('physicist', 0.011430762201661462),\n",
       " ('astronomy', 0.010728765181343468),\n",
       " ('neuroscience', 0.008827462002388348),\n",
       " ('infection', 0.0068917694253083995)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def connectivity_ranking(G, nodes_community, communities, communities_count):\n",
    "    ''' input: G:nx.Graph \n",
    "               nodes_community:{node_id:community_id}\n",
    "               communities:[community_ids]\n",
    "               community_count:int\n",
    "       output: communities_ranking:{community_id:ranking}\n",
    "\n",
    "    '''\n",
    "    communities_ranking = default_ranking.copy()\n",
    "    \n",
    "    meta_G = nx.Graph()\n",
    "    w_matrix = {c2:{c1:0 for c1 in communities} for c2 in communities}\n",
    "    for (n1, n2, weight) in G.edges(data='Weight'):\n",
    "        w_matrix[nodes_community[n1]][nodes_community[n2]] += weight\n",
    "#     meta_G.add_nodes_from(communities)\n",
    "    for c1 in w_matrix:\n",
    "        for c2 in w_matrix[c1]:\n",
    "            if w_matrix[c1][c2] != 0 and c1 != c2:\n",
    "                meta_G.add_edge(c1, c2, weight=w_matrix[c1][c2])\n",
    "    communities_ranking = nx.pagerank(meta_G)\n",
    "    return communities_ranking\n",
    "\n",
    "connectivity_ranking = connectivity_ranking(G, nodes_community, communities, communities_count)\n",
    "sorted(connectivity_ranking.items(), key=lambda x: x[1], reverse=True) if connectivity_ranking != default_ranking else None # prints sorted results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Personalized Community Ranking\n",
    "- Compute, for each community, the **personalized pagerank** of its **influencer**, where the source nodes belong to the community **artificial intelligence**.\n",
    "- Hint: Useful function: `nx.pagerank()`; `personalization` parameter defines the probability of random jumping to a source node.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('artificial intelligence', 0.008473520980562959),\n",
       " ('computer science', 0.005335564667709074),\n",
       " ('climate change', 0.0028914310327644134),\n",
       " ('architecture', 0.0026683018017832683),\n",
       " ('drones', 0.0026683018017832683),\n",
       " ('psychology', 0.0022192418960173157),\n",
       " ('entrepreneurship', 0.002195077423385992),\n",
       " ('pathways', 0.0005144881831279561),\n",
       " ('patients', 0.0004385223746859665),\n",
       " ('chemistry', 2.7703523886347134e-06),\n",
       " ('physics', 2.162496306612547e-06),\n",
       " ('innovation', 1.8889741877389747e-06),\n",
       " ('physicist', 1.7810328800477428e-06),\n",
       " ('criminology', 1.6622973700554927e-06),\n",
       " ('robotics', 1.0389358574629546e-06),\n",
       " ('astronomy', 1.0389358574629546e-06),\n",
       " ('neuroscience', 1.0389358574629546e-06),\n",
       " ('diabetes', 1.0389358574629546e-06),\n",
       " ('cyber security', 1.0389358574629546e-06),\n",
       " ('biological', 1.0389358574629546e-06),\n",
       " ('therapy', 1.0389358574629546e-06),\n",
       " ('infection', 1.038935857462954e-06),\n",
       " ('cell', 1.0389358574629538e-06),\n",
       " ('healthcare', 1.0389358574629533e-06),\n",
       " ('sustainability', 1.0389358574629533e-06),\n",
       " ('geography', 1.0389358574629533e-06),\n",
       " ('economics', 1.0389358574629533e-06),\n",
       " ('medicine', 1.0389358574629533e-06),\n",
       " ('cancer', 1.0389358574629533e-06),\n",
       " ('social media', 1.038935857462952e-06)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def personalized_ranking(G, nodes_community, communities, communities_count):\n",
    "    ''' input: G:nx.Graph \n",
    "               nodes_community:{node_id:community_id}\n",
    "               communities:[community_ids]\n",
    "               community_count:int\n",
    "       output: communities_ranking:{community_id:ranking}\n",
    "\n",
    "    '''\n",
    "    communities_ranking = default_ranking.copy()\n",
    "    influencers = community_influencers(G, nodes_community, communities, communities_count)\n",
    "\n",
    "    #create personalization dict\n",
    "    #where value of a  person is 1/(total people in IA) if belongs in IA, else 0\n",
    "    personalization = {}\n",
    "    for node in nodes_community:\n",
    "        personalization[node] = 1 if nodes_community[node] == \"artificial intelligence\" else 0\n",
    "    \n",
    "    # normalize\n",
    "    total_members_artificial = sum(personalization.values())\n",
    "    for node in personalization:\n",
    "        personalization[node] = personalization[node] / total_members_artificial  \n",
    "    \n",
    "    pers_pagerank = nx.pagerank(G, personalization=personalization)\n",
    "    for commun in communities:\n",
    "        communities_ranking[commun] = pers_pagerank[influencers[commun]]\n",
    "    \n",
    "    return communities_ranking\n",
    " \n",
    "personalized_ranking = personalized_ranking(G, nodes_community, communities, communities_count)\n",
    "sorted(personalized_ranking.items(), key=lambda x: x[1], reverse=True) if personalized_ranking != default_ranking else None # prints sorted results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 TF-IDF Community Ranking\n",
    "- Treat each community as a document.\n",
    "- Treat **artificial intelligence** as a query.\n",
    "- Rank the documents (communities) based on their similarity to the query.\n",
    "- Hint: Useful function: `cosine_similarity()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "# compute IDF, storing idf values in a dictionary\n",
    "def idf_values(vocabulary, documents):\n",
    "    idf = {}\n",
    "    num_documents = len(documents)\n",
    "    for i, term in enumerate(vocabulary):\n",
    "        idf[term] = math.log(num_documents/sum(term in document for document in documents), math.e)\n",
    "    return idf\n",
    "\n",
    "# Function to generate the vector for a document (with normalisation)\n",
    "def vectorize(document, vocabulary, idf):\n",
    "    vector = [0]*len(vocabulary)\n",
    "    counts = Counter(document)\n",
    "    max_count = counts.most_common(1)[0][1]\n",
    "    for i,term in enumerate(vocabulary):\n",
    "        vector[i] = idf[term] * counts[term]/max_count\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('artificial intelligence', 0.9994329110021056),\n",
       " ('computer science', 0.11692586302105945),\n",
       " ('drones', 0.06578367513899608),\n",
       " ('innovation', 0.0626339241649355),\n",
       " ('healthcare', 0.03830806444554278),\n",
       " ('psychology', 0.03248205047416097),\n",
       " ('entrepreneurship', 0.029233699815882905),\n",
       " ('chemistry', 0.02386657957481061),\n",
       " ('architecture', 0.016607359013533222),\n",
       " ('climate change', 0.011953107314117799),\n",
       " ('cell', 0.007619251962086645),\n",
       " ('social media', 0.0010458888348641236),\n",
       " ('pathways', 0.0),\n",
       " ('physics', 0.0),\n",
       " ('robotics', 0.0),\n",
       " ('astronomy', 0.0),\n",
       " ('patients', 0.0),\n",
       " ('sustainability', 0.0),\n",
       " ('geography', 0.0),\n",
       " ('economics', 0.0),\n",
       " ('medicine', 0.0),\n",
       " ('neuroscience', 0.0),\n",
       " ('diabetes', 0.0),\n",
       " ('cyber security', 0.0),\n",
       " ('infection', 0.0),\n",
       " ('criminology', 0.0),\n",
       " ('physicist', 0.0),\n",
       " ('biological', 0.0),\n",
       " ('cancer', 0.0),\n",
       " ('therapy', 0.0)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tfidf_ranking(G, nodes_community, communities, communities_count):\n",
    "    ''' input: G:nx.Graph \n",
    "               nodes_community:{node_id:community_id}\n",
    "               communities:[community_ids]\n",
    "               community_count:int\n",
    "       output: communities_ranking:{community_id:ranking}\n",
    "\n",
    "    '''\n",
    "    communities_ranking = default_ranking.copy()\n",
    "\n",
    "    documents = [''] * communities_count\n",
    "    query = ['artificial intelligence']\n",
    "    \n",
    "    for n in nodes_community:\n",
    "        labels = ''.join([str(e[2]['Label'] + ' ')*e[2]['Weight'] for e in G.edges(n, data=True)])\n",
    "        documents[communities.index(nodes_community[n])] += labels\n",
    "    \n",
    "    #creating vocabulary\n",
    "    vocabulary = []\n",
    "    for d in documents:\n",
    "        for w in d.split():\n",
    "            if w not in vocabulary:\n",
    "                vocabulary.append(w)\n",
    "    docs_splitted = [d.split() for d in documents]\n",
    "    \n",
    "    # creating document vectors\n",
    "    idf = idf_values(vocabulary, docs_splitted)\n",
    "    document_vectors = [vectorize(s, vocabulary, idf) for s in docs_splitted]\n",
    "    \n",
    "    #creating query vector\n",
    "    query_vector = vectorize(query[0].split(), vocabulary, idf)\n",
    "    \n",
    "    #compute similarity\n",
    "    sim = cosine_similarity([query_vector]*len(document_vectors), document_vectors)[0]\n",
    "    for id, commun in enumerate(communities):\n",
    "        communities_ranking[commun] = sim[id]\n",
    "    return communities_ranking\n",
    "\n",
    "tfidf_ranking = tfidf_ranking(G, nodes_community, communities, communities_count)\n",
    "sorted(tfidf_ranking.items(), key=lambda x: x[1], reverse=True) if tfidf_ranking != default_ranking else None # prints sorted results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 Rankings Correlation\n",
    "- Consider `personalized_ranking`, `tfidf_ranking` and `AVG(connectivity_ranking, tfidf_ranking)`.\n",
    "- Compute the `3x3` correlation matrix.\n",
    "- Discuss which rankings correlate more and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_correlation(connectivity_ranking, personalized_ranking, tfidf_ranking):    \n",
    "    correlation = np.zeros([3,3])\n",
    "    \n",
    "    connectivity_ranking = [r[1] for r in sorted(connectivity_ranking.items(), key=lambda x: x[0])]\n",
    "    personalized_ranking = [r[1] for r in sorted(personalized_ranking.items(), key=lambda x: x[0])]\n",
    "    tfidf_ranking = [r[1] for r in sorted(tfidf_ranking.items(), key=lambda x: x[0])]\n",
    "    avg_connectivity_tfidf_ranking = [sum(x)/2 for x in zip(connectivity_ranking, tfidf_ranking)]\n",
    "    \n",
    "    # Add your code here    \n",
    "    \n",
    "    return correlation\n",
    "\n",
    "compute_correlation(connectivity_ranking, personalized_ranking, tfidf_ranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***ANSWER:***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 [Submit  your Notebook](https://moodle.epfl.ch/mod/quiz/view.php?id=1026302)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "name": "_merged",
  "toc": {
   "base_numbering": "0",
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Table of Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
